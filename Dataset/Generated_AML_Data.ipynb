{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvuvt3bGei_x",
        "outputId": "8cf13418-7631-4dda-ad6d-6a83ff23baca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Faker\n",
            "  Downloading Faker-30.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from Faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
            "Downloading Faker-30.8.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faker\n",
            "Successfully installed Faker-30.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from datetime import datetime\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def generate_sanctioned_entities():\n",
        "    global sanctioned_countries\n",
        "    # List of sanctioned countries\n",
        "    sanctioned_countries = [\"Russia\", \"China\", \"North Korea\", \"Cuba\", \"Myanmar\", \"Venezuela\", \"Panama\"]\n",
        "\n",
        "    # Define specific risk levels for each country\n",
        "    country_risk_mapping = {\n",
        "        \"Russia\": \"High\", \"China\": \"Medium\",\n",
        "        \"North Korea\": \"High\", \"Cuba\": \"Medium\",\n",
        "        \"Venezuela\": \"Medium\", \"Panama\": \"Low\"\n",
        "    }\n",
        "\n",
        "    sanctioned_entities_data = []\n",
        "\n",
        "    for i in range(1, len(sanctioned_countries) + 1):\n",
        "        sanction_id = f\"SANC{i:04d}\"\n",
        "        entity_name = f\"Entity {fake.company()}\"\n",
        "        country = sanctioned_countries[i - 1]\n",
        "        risk_level = country_risk_mapping[country]  # Assign risk level based on country mapping\n",
        "        blacklist_date = fake.date_between(start_date='-10y', end_date='today')\n",
        "\n",
        "        sanctioned_entities_data.append([sanction_id, entity_name, country, risk_level, blacklist_date])\n",
        "\n",
        "    sanctioned_entities_df1 = pd.DataFrame(sanctioned_entities_data, columns=[\n",
        "        \"SanctionID\", \"EntityName\", \"Country\", \"RiskLevel\", \"BlacklistDate\"\n",
        "    ])\n",
        "\n",
        "    return sanctioned_entities_df1"
      ],
      "metadata": {
        "id": "8jatzA-fmmYl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kgZWiYDPtve6"
      },
      "outputs": [],
      "source": [
        "def generate_customer_data(num_customers):\n",
        "    customer_data = []\n",
        "    global countries, sanctioned_countries\n",
        "\n",
        "    job_titles = [\"Engineer\", \"Doctor\", \"Teacher\", \"Software Developer\", \"Data Scientist\",\n",
        "                  \"Banker\", \"Consultant\", \"Artist\", \"Freelancer\", \"Manager\", \"Sales Executive\"]\n",
        "    countries = [\"USA\", \"Germany\", \"France\", \"Japan\", \"India\", \"Brazil\", \"UK\", \"Canada\"]\n",
        "    sanctioned_countries = [\"Russia\", \"China\", \"North Korea\", \"Cuba\", \"Venezuela\", \"Panama\"]\n",
        "    customer_account_types = [\"Personal\", \"Business\", \"VIP\", \"Basic\"]\n",
        "    account_types = [\"Loan\", \"Investment\", \"Saving\", \"Retirement\"]\n",
        "\n",
        "    for i in range(1000, num_customers+1000):\n",
        "        customer_id = f\"CUST{i:06d}\"\n",
        "        account_id = f\"ACC{i:06d}\"\n",
        "        customer_name = fake.name()\n",
        "        dob = fake.date_of_birth(minimum_age=18, maximum_age=60)\n",
        "        country = random.choice(countries)\n",
        "        address = fake.address()\n",
        "        gender = random.choice([\"Male\", \"Female\"])\n",
        "        job_title = random.choice(job_titles)\n",
        "        AccountType = random.choice(account_types)\n",
        "        CustomerAccount = random.choice(customer_account_types)\n",
        "\n",
        "        # Salary will depend on the job title\n",
        "        if job_title in [\"Engineer\", \"Doctor\", \"Software Developer\", \"Data Scientist\"]:\n",
        "            salary = round(random.uniform(50000, 200000), 2)\n",
        "        elif job_title in [\"Teacher\", \"Artist\", \"Freelancer\"]:\n",
        "            salary = round(random.uniform(30000, 80000), 2)\n",
        "        else:\n",
        "            salary = round(random.uniform(40000, 150000), 2)\n",
        "\n",
        "        customer_data.append([customer_id, account_id, customer_name, dob, country, address, gender, job_title, salary, AccountType, CustomerAccount])\n",
        "    customer_df = pd.DataFrame(customer_data, columns=[\n",
        "        \"CustomerID\", \"AccountID\", \"CustomerName\", \"DateOfBirth\", \"Country\", \"Address\", \"Gender\", \"JobTitle\", \"Salary\", \"AccountType\", \"CustomerAccount\"\n",
        "    ])\n",
        "    return customer_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNc4Dr3-elAp"
      },
      "outputs": [],
      "source": [
        "def generate_unique_transaction_ids(num_transactions):\n",
        "    transaction_ids = [f\"TRANS{i:06d}\" for i in range(1000, num_transactions + 1000)]\n",
        "    return list(transaction_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Lglj7JDYf5"
      },
      "outputs": [],
      "source": [
        "def generate_transactions(customer_df, transaction_ids, num_transactions_per_customer=20):\n",
        "    transaction_data = []\n",
        "    transaction_types = [\"Deposit\", \"Withdrawal\", \"Transfer\", \"Payment\"]\n",
        "\n",
        "    transaction_idx = 0\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        account_id = customer['AccountID']\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            if transaction_idx >= len(transaction_ids):\n",
        "                raise IndexError(f\"Not enough transaction IDs for the total number of transactions required!\")\n",
        "\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1  # Move to the next ID\n",
        "            transaction_date = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "            transaction_type = random.choice(transaction_types)\n",
        "\n",
        "            # Usual transactions: 50 - 100,000, but 35% above 500,000 for anomaly detection\n",
        "            if random.random() < 0.35:\n",
        "                transaction_amount = round(random.uniform(500000, 1000000), 2)\n",
        "            else:\n",
        "                transaction_amount = round(random.uniform(50, 100000), 2)\n",
        "\n",
        "            transaction_location = random.choice(countries + sanctioned_countries)\n",
        "\n",
        "            transaction_data.append([\n",
        "                transaction_id, customer_id, account_id, transaction_date, transaction_type, transaction_amount, transaction_location\n",
        "            ])\n",
        "\n",
        "    transaction_df = pd.DataFrame(transaction_data, columns=[\n",
        "        \"TransactionID\", \"CustomerID\", \"AccountID\", \"TransactionDate\", \"TransactionType\", \"TransactionAmount\", \"TransactionLocation\"\n",
        "    ])\n",
        "\n",
        "    return transaction_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4eAjnyuzUPI"
      },
      "outputs": [],
      "source": [
        "def generate_cross_border_transactions(customer_df, transaction_ids, num_transactions_per_customer=20):\n",
        "    cross_border_data = []\n",
        "    transaction_types = [\"Deposit\", \"Withdrawal\", \"Transfer\", \"Payment\"]\n",
        "\n",
        "    transaction_idx = 0\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        account_id = customer['AccountID']\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1\n",
        "            transaction_date = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "            transaction_type = random.choice(transaction_types)\n",
        "\n",
        "            # Normal and large transactions\n",
        "            if random.random() < 0.4:\n",
        "                transaction_amount = round(random.uniform(500000, 1000000), 2)\n",
        "            else:\n",
        "                transaction_amount = round(random.uniform(50, 100000), 2)\n",
        "\n",
        "            # 30% of customers have transactions in sanctioned countries\n",
        "            if random.random() < 0.3:\n",
        "                transaction_location = random.choice(sanctioned_countries)\n",
        "            else:\n",
        "                transaction_location = random.choice(countries)\n",
        "\n",
        "            cross_border_data.append([\n",
        "                transaction_id, customer_id, account_id, transaction_date, transaction_type, transaction_amount, transaction_location\n",
        "            ])\n",
        "\n",
        "    cross_border_df = pd.DataFrame(cross_border_data, columns=[\n",
        "        \"TransactionID\", \"CustomerID\", \"AccountID\", \"TransactionDate\", \"TransactionType\", \"TransactionAmount\", \"TransactionLocation\"\n",
        "    ])\n",
        "\n",
        "    return cross_border_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cM8wEnGs0xL"
      },
      "outputs": [],
      "source": [
        "# Generate Sanctioned Entities Transactions\n",
        "def generate_sanctioned_entities_transactions(customer_df, transaction_ids, num_transactions_per_customer=20):\n",
        "    sanctioned_entities_data = []\n",
        "\n",
        "    transaction_idx = 0\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        customer_name = customer['CustomerName']\n",
        "        customer_country = customer['Country']\n",
        "        customer_dob = customer['DateOfBirth']\n",
        "\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1\n",
        "            transaction_date = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "\n",
        "            # 30% of customers have transactions in sanctioned countries\n",
        "            if random.random() < 0.3:\n",
        "                transaction_location = random.choice(sanctioned_countries)\n",
        "            else:\n",
        "                transaction_location = customer_country  # Normal country for the customer\n",
        "\n",
        "            sanctioned_entities_data.append([\n",
        "                transaction_id, customer_id, customer_name, customer_country, customer_dob, transaction_date, transaction_location\n",
        "            ])\n",
        "\n",
        "    sanctioned_entities_df = pd.DataFrame(sanctioned_entities_data, columns=[\n",
        "        \"TransactionID\", \"CustomerID\", \"CustomerName\", \"Country\", \"DateOfBirth\", \"TransactionDate\", \"TransactionLocation\"\n",
        "    ])\n",
        "\n",
        "    return sanctioned_entities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEawTuUttAl2"
      },
      "outputs": [],
      "source": [
        "# Generate Unmatched Accounts Transactions\n",
        "def generate_unmatched_accounts(customer_df, transaction_ids, num_transactions_per_customer=1):\n",
        "    unmatched_data = []\n",
        "    transaction_idx = 0\n",
        "\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        account_id = customer['AccountID']\n",
        "        account_balance = round(random.uniform(10000, 500000), 2)  # Initial account balance\n",
        "        open_date = fake.date_between(start_date=\"-5y\", end_date=\"-1y\")\n",
        "\n",
        "        # Randomly decide if the account is still open or closed for a short period\n",
        "        if random.random() < 0.30:  # 30% of accounts closed shortly after opening\n",
        "            close_date = fake.date_between(start_date=open_date, end_date=open_date + timedelta(days=30))\n",
        "        elif random.random() < 0.4:  # 40% of accounts closed later\n",
        "            close_date = fake.date_between(start_date=open_date, end_date=\"today\")\n",
        "        else:  # 30% of accounts remain open (no close date)\n",
        "            close_date = None\n",
        "\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1\n",
        "            end_date = close_date if close_date else datetime.now().date()\n",
        "            transaction_date = fake.date_time_between(start_date=open_date, end_date=end_date)\n",
        "            transaction_amount = round(random.uniform(50, 50000), 2)\n",
        "\n",
        "            # Deduct transaction amount from account balance\n",
        "            account_balance -= transaction_amount\n",
        "\n",
        "            unmatched_data.append([\n",
        "                account_id, customer_id, open_date, close_date, account_balance, transaction_id, transaction_amount, transaction_date\n",
        "            ])\n",
        "\n",
        "    unmatched_df = pd.DataFrame(unmatched_data, columns=[\n",
        "        \"AccountID\", \"CustomerID\", \"OpenDate\", \"CloseDate\", \"AccountBalance\", \"TransactionID\", \"TransactionAmount\", \"TransactionDate\"\n",
        "    ])\n",
        "\n",
        "    return unmatched_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQriuKPOtBQX"
      },
      "outputs": [],
      "source": [
        "# Generate Customer Behavior Transactions\n",
        "def generate_customer_behavior_transactions(customer_df, transaction_ids, num_transactions_per_customer=20):\n",
        "    behavior_data = []\n",
        "    transaction_idx = 0\n",
        "\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1\n",
        "            transaction_date = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "\n",
        "            # Regular transactions, with occasional spikes\n",
        "            if random.random() < 0.4:\n",
        "                transaction_amount = round(random.uniform(100000, 500000), 2)\n",
        "            else:\n",
        "                transaction_amount = round(random.uniform(50, 10000), 2)\n",
        "\n",
        "            behavior_data.append([\n",
        "                transaction_id, customer_id, transaction_amount, transaction_date\n",
        "            ])\n",
        "\n",
        "    behavior_df = pd.DataFrame(behavior_data, columns=[\n",
        "        \"TransactionID\", \"CustomerID\", \"TransactionAmount\", \"TransactionDate\"\n",
        "    ])\n",
        "\n",
        "    return behavior_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQIbJ5rwtfGU"
      },
      "outputs": [],
      "source": [
        "# Generate Time Gap Transactions\n",
        "def generate_time_gap_transactions(customer_df, transaction_ids, num_transactions_per_customer=20):\n",
        "    time_gap_data = []\n",
        "    transaction_idx = 0\n",
        "\n",
        "    for _, customer in customer_df.iterrows():\n",
        "        customer_id = customer['CustomerID']\n",
        "        prev_transaction_date = None\n",
        "        for j in range(num_transactions_per_customer):\n",
        "            transaction_id = transaction_ids[transaction_idx]  # Use existing TransactionID\n",
        "            transaction_idx += 1\n",
        "\n",
        "            # Generate small time gaps for some transactions and large for others\n",
        "            if prev_transaction_date:\n",
        "                if random.random() < 0.5:  # Small gap (same day)\n",
        "                    transaction_date = prev_transaction_date + timedelta(hours=random.randint(1, 6))\n",
        "                else:  # Next day\n",
        "                    transaction_date = prev_transaction_date + timedelta(days=1)\n",
        "            else:\n",
        "                transaction_date = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "\n",
        "            prev_transaction_date = transaction_date\n",
        "            time_gap_data.append([transaction_id, customer_id, transaction_date])\n",
        "\n",
        "    time_gap_df = pd.DataFrame(time_gap_data, columns=[\"TransactionID\", \"CustomerID\", \"TransactionDate\"])\n",
        "\n",
        "    return time_gap_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km96pP4htnFg"
      },
      "outputs": [],
      "source": [
        "import xlsxwriter\n",
        "# Number of customers and transactions per customer\n",
        "num_customers = 20000\n",
        "num_transactions_per_customer = 20\n",
        "total_transactions = num_customers * num_transactions_per_customer\n",
        "\n",
        "\n",
        "# Generate unique transaction IDs\n",
        "transaction_ids = generate_unique_transaction_ids(total_transactions)\n",
        "\n",
        "# Generate data with consistent TransactionIDs\n",
        "df = generate_sanctioned_entities()\n",
        "customer_df = generate_customer_data(num_customers)\n",
        "transaction_df = generate_transactions(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "cross_border_df = generate_cross_border_transactions(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "behavior_df = generate_customer_behavior_transactions(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "time_gap_df = generate_time_gap_transactions(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "unmatched_df = generate_unmatched_accounts(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "sanctioned_entities_df = generate_sanctioned_entities_transactions(customer_df, transaction_ids, num_transactions_per_customer)\n",
        "\n",
        "# Export all tables to Excel\n",
        "with pd.ExcelWriter(\"AML_synthetic_data.xlsx\", engine='xlsxwriter') as writer:\n",
        "    df.to_excel(writer, sheet_name=\"Sanctioned_Entities.csv\", index=False)\n",
        "    customer_df.to_excel(writer, sheet_name=\"Customer_Informations\", index=False)\n",
        "    transaction_df.to_excel(writer, sheet_name=\"Unusual_Transactions\", index=False)\n",
        "    cross_border_df.to_excel(writer, sheet_name=\"Cross_Border_Transactions\", index=False)\n",
        "    behavior_df.to_excel(writer, sheet_name=\"Customer_Behavior\", index=False)\n",
        "    time_gap_df.to_excel(writer, sheet_name=\"Time_Gap_Transactions\", index=False)\n",
        "    unmatched_df.to_excel(writer, sheet_name=\"Unmatched_Accounts\", index=False)\n",
        "    sanctioned_entities_df.to_excel(writer, sheet_name=\"Sanctioned_Entities_Matching\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56LosB_lIQcG"
      },
      "outputs": [],
      "source": [
        "customer_df.to_csv(\"Customer_Information.csv\", index=False)\n",
        "transaction_df.to_csv(\"Unusual_Transactions.csv\", index=False)\n",
        "cross_border_df.to_csv(\"Cross_Border_Transactions.csv\", index=False)\n",
        "behavior_df.to_csv(\"Customer_Behavior.csv\", index=False)\n",
        "time_gap_df.to_csv(\"Time_Gap_Transactions.csv\", index=False)\n",
        "unmatched_df.to_csv(\"Unmatched_Accounts.csv\", index=False)\n",
        "sanctioned_entities_df.to_csv(\"Sanctioned_Entities_Matching.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_path = 'AML_synthetic_data.xlsx'\n",
        "account_types = [\"Loan\", \"Investment\", \"Saving\", \"Retirement\"]\n",
        "\n",
        "# Load the customer information sheet\n",
        "customer_info_df = pd.read_excel(file_path, sheet_name='Customer_Information')\n",
        "\n",
        "# Add the 'AccountType' column with random values\n",
        "customer_info_df['AccountType'] = [random.choice(account_types) for _ in range(len(customer_info_df))]\n",
        "\n",
        "# Save the updated data into a new sheet in the same Excel file\n",
        "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
        "    customer_info_df.to_excel(writer, sheet_name='Customer_Inforomation', index=False)\n",
        "\n",
        "print(\"AccountType column added and saved to a new sheet in the existing Excel file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iy9-9JIGfi_",
        "outputId": "d84eb99e-d2bd-419d-871a-1a58625a1225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AccountType column added and saved to a new sheet in the existing Excel file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_banks(num_banks):\n",
        "    bank_data = []\n",
        "\n",
        "    # List of example countries\n",
        "    countries = [\n",
        "        \"USA\", \"Canada\", \"UK\", \"Germany\", \"France\", \"Italy\",\n",
        "        \"Spain\", \"Australia\", \"Japan\", \"China\", \"India\", \"Brazil\",\n",
        "        \"South Africa\", \"Mexico\", \"Russia\", \"Netherlands\", \"Sweden\",\n",
        "        \"Switzerland\", \"Singapore\", \"New Zealand\", \"Turkey\"\n",
        "    ]\n",
        "\n",
        "    for i in range(1, num_banks + 1):\n",
        "        bank_id = f\"BANK{i:04d}\"  # Create unique BankID\n",
        "        bank_name = fake.company()  # Generate random bank name\n",
        "        bank_country = random.choice(countries)  # Randomly select a country\n",
        "        branch_name = fake.city()  # Generate random branch name\n",
        "\n",
        "        bank_data.append([bank_id, bank_name, bank_country, branch_name])\n",
        "\n",
        "    # Create DataFrame\n",
        "    banks_df = pd.DataFrame(bank_data, columns=[\"BankID\", \"BankName\", \"BankCountry\", \"BranchName\"])\n",
        "\n",
        "    return banks_df\n",
        "\n",
        "# Generate 60 banks\n",
        "banks_df = generate_banks(60)\n",
        "\n",
        "# Save to Excel\n",
        "banks_df.to_excel(\"Synthetic_Bank_Data.xlsx\", index=False)\n",
        "\n",
        "print(\"Synthetic bank data generated and saved in CSV, Excel, and XML formats.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z9Dhy-glvNH",
        "outputId": "c07dd308-66a7-4417-e220-d62f75cf4b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic bank data generated and saved in CSV, Excel, and XML formats.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}